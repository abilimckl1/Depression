{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c41b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baaac67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:\\\\CDS503\\\\Assignment 1\\\\Depression'\n",
    "os.chdir(path)\n",
    "\n",
    "# Read csv data file\n",
    "# Data without feature standardization\n",
    "df_freq = pd.read_csv('Freq-PHO-Binary.csv')\n",
    "df_norm = pd.read_csv('Norm-PHO-Binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d391f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "# Create LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Convert string categories into numbers for gender and depression\n",
    "df_freq['Gender'] = le.fit_transform(df_freq['Gender'])\n",
    "df_freq['Depression'] = le.fit_transform(df_freq['Depression'])\n",
    "df_norm['Gender'] = le.fit_transform(df_norm['Gender'])\n",
    "df_norm['Depression'] = le.fit_transform(df_norm['Depression'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ecfdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion_Joy</th>\n",
       "      <th>Emotion_Sadness</th>\n",
       "      <th>Emotion_Anger</th>\n",
       "      <th>Emotion_Disgust</th>\n",
       "      <th>Emotion_Fear</th>\n",
       "      <th>Emotion_Surprise</th>\n",
       "      <th>Emotion_Contempt</th>\n",
       "      <th>Emotion_Neutral</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Emotion_Joy  Emotion_Sadness  Emotion_Anger  Emotion_Disgust  \\\n",
       "0       0            4                3              2                1   \n",
       "1       0            8                0              2                0   \n",
       "2       1            5                0              0                0   \n",
       "3       1            7                0              3                0   \n",
       "4       1            3                2              1                0   \n",
       "\n",
       "   Emotion_Fear  Emotion_Surprise  Emotion_Contempt  Emotion_Neutral  \\\n",
       "0             0                 2                 2                1   \n",
       "1             1                 0                 0                4   \n",
       "2            14                 2                 0               15   \n",
       "3             0                 5                 0                0   \n",
       "4             2                 1                 0                6   \n",
       "\n",
       "   Depression  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0746c7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion_Joy</th>\n",
       "      <th>Emotion_Sadness</th>\n",
       "      <th>Emotion_Anger</th>\n",
       "      <th>Emotion_Disgust</th>\n",
       "      <th>Emotion_Fear</th>\n",
       "      <th>Emotion_Surprise</th>\n",
       "      <th>Emotion_Contempt</th>\n",
       "      <th>Emotion_Neutral</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.17</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Emotion_Joy  Emotion_Sadness  Emotion_Anger  Emotion_Disgust  \\\n",
       "0       0         4.00              3.0            2.0              1.0   \n",
       "1       0         8.00              0.0            2.0              0.0   \n",
       "2       1         1.67              0.0            0.0              0.0   \n",
       "3       1         7.00              0.0            3.0              0.0   \n",
       "4       1         3.00              2.0            1.0              0.0   \n",
       "\n",
       "   Emotion_Fear  Emotion_Surprise  Emotion_Contempt  Emotion_Neutral  \\\n",
       "0          0.00              2.00               2.0              1.0   \n",
       "1          1.00              0.00               0.0              4.0   \n",
       "2          6.17              0.67               0.0              6.5   \n",
       "3          0.00              5.00               0.0              0.0   \n",
       "4          2.00              1.00               0.0              6.0   \n",
       "\n",
       "   Depression  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d3883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender              int32\n",
       "Emotion_Joy         int64\n",
       "Emotion_Sadness     int64\n",
       "Emotion_Anger       int64\n",
       "Emotion_Disgust     int64\n",
       "Emotion_Fear        int64\n",
       "Emotion_Surprise    int64\n",
       "Emotion_Contempt    int64\n",
       "Emotion_Neutral     int64\n",
       "Depression          int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373f0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df_freq = df_freq['Depression']\n",
    "target_df_norm = df_norm['Depression']\n",
    "\n",
    "features_df_freq = df_freq.drop(['Depression'], axis=1)\n",
    "features_df_norm = df_norm.drop(['Depression'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b6f5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    186\n",
       "1    160\n",
       "Name: Depression, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_count = target_df_freq.value_counts()\n",
    "depression_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce078aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     186\n",
       "Yes    160\n",
       "Name: Depression, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_count = depression_count.rename(index={0:'No',1:'Yes'})\n",
    "depression_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7176cbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No', 'Yes'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ab60e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myexplode = [0.05, 0]\n",
    "mycolors = ['orange','blue']\n",
    "plt.pie(depression_count, explode = myexplode, colors = mycolors, autopct='%1.1f%%')\n",
    "plt.legend(depression_count.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5267d0",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26870e2",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb40b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b50e39",
   "metadata": {},
   "source": [
    "#### Run this for Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7050d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features_df_freq, target_df_freq, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e8b81",
   "metadata": {},
   "source": [
    "#### Run this for Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce68b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features_df_norm, target_df_norm, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09587725",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2dea2",
   "metadata": {},
   "source": [
    "## 3 Classifications + Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b4714",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446f8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "dummy_classifier = DummyClassifier(strategy='uniform')\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d491b",
   "metadata": {},
   "source": [
    "### Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9c61fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Dummy:  0.5544973544973545\n",
      "Test Accuracy Dummy (Freq):  0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dummy_classifier, x_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "print('Validation Accuracy Dummy: ', scores.mean())\n",
    "\n",
    "dummy_classifier.fit(x_train, y_train)\n",
    "test_predict = dummy_classifier.predict(x_test)\n",
    "\n",
    "print(\"Test Accuracy Dummy (Freq): \", metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9eac8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d24b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20 17]\n",
      " [19 14]]\n",
      "\t\t\tDummy Classifier w Freq Dataset\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.53        37\n",
      "           1       0.45      0.42      0.44        33\n",
      "\n",
      "    accuracy                           0.49        70\n",
      "   macro avg       0.48      0.48      0.48        70\n",
      "weighted avg       0.48      0.49      0.48        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "\n",
    "# Print precision, recall and F1\n",
    "print(\"\\t\\t\\tDummy Classifier w Freq Dataset\\n\", classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aef881",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec9894",
   "metadata": {},
   "source": [
    "### Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7272a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Dummy:  0.4780423280423281\n",
      "Test Accuracy Dummy (Norm):  0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dummy_classifier, x_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "print('Validation Accuracy Dummy: ', scores.mean())\n",
    "\n",
    "dummy_classifier.fit(x_train, y_train)\n",
    "test_predict = dummy_classifier.predict(x_test)\n",
    "\n",
    "print(\"Test Accuracy Dummy (Norm): \", metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c942714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 20]\n",
      " [14 19]]\n",
      "\t\t\tDummy Classifier w Norm Dataset\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.46      0.50        37\n",
      "           1       0.49      0.58      0.53        33\n",
      "\n",
      "    accuracy                           0.51        70\n",
      "   macro avg       0.52      0.52      0.51        70\n",
      "weighted avg       0.52      0.51      0.51        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "\n",
    "# Print precision, recall and F1\n",
    "print(\"\\t\\t\\tDummy Classifier w Norm Dataset\\n\", classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75a885",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cbc67",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8f71b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba78005",
   "metadata": {},
   "source": [
    "### Freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5e33d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 1\n",
      "Fold:  5\n",
      "K- 1 Validation/Test Score average (Norm):  0.5179220779220779 / 0.5571428571428572\n",
      "K- 2 Validation/Test Score average (Norm):  0.510909090909091 / 0.5714285714285714\n",
      "K- 3 Validation/Test Score average (Norm):  0.5177272727272728 / 0.5428571428571428\n",
      "K- 4 Validation/Test Score average (Norm):  0.517987012987013 / 0.5428571428571428\n",
      "K- 5 Validation/Test Score average (Norm):  0.5251948051948052 / 0.5714285714285714\n",
      "K- 6 Validation/Test Score average (Norm):  0.5397402597402597 / 0.5857142857142857\n",
      "K- 7 Validation/Test Score average (Norm):  0.536103896103896 / 0.6\n",
      "K- 8 Validation/Test Score average (Norm):  0.5287662337662338 / 0.6\n",
      "K- 9 Validation/Test Score average (Norm):  0.5324025974025974 / 0.6142857142857143\n",
      "K- 10 Validation/Test Score average (Norm):  0.5611038961038961 / 0.5571428571428572\n",
      "K- 11 Validation/Test Score average (Norm):  0.5466883116883118 / 0.6142857142857143\n",
      "K- 12 Validation/Test Score average (Norm):  0.5433116883116883 / 0.5571428571428572\n",
      "K- 13 Validation/Test Score average (Norm):  0.5577922077922077 / 0.5857142857142857\n",
      "K- 14 Validation/Test Score average (Norm):  0.5287662337662338 / 0.5428571428571428\n",
      "K- 15 Validation/Test Score average (Norm):  0.5577272727272727 / 0.6\n",
      "K- 16 Validation/Test Score average (Norm):  0.5614285714285714 / 0.6\n",
      "K- 17 Validation/Test Score average (Norm):  0.546883116883117 / 0.5571428571428572\n",
      "K- 18 Validation/Test Score average (Norm):  0.5688311688311687 / 0.5857142857142857\n",
      "K- 19 Validation/Test Score average (Norm):  0.5796753246753247 / 0.5857142857142857\n",
      "K- 20 Validation/Test Score average (Norm):  0.5542207792207792 / 0.6142857142857143\n",
      "K- 21 Validation/Test Score average (Norm):  0.5577272727272727 / 0.5714285714285714\n",
      "K- 22 Validation/Test Score average (Norm):  0.547077922077922 / 0.6285714285714286\n",
      "K- 23 Validation/Test Score average (Norm):  0.5579220779220779 / 0.6428571428571429\n",
      "K- 24 Validation/Test Score average (Norm):  0.5615584415584415 / 0.6142857142857143\n",
      "K- 25 Validation/Test Score average (Norm):  0.5542857142857143 / 0.6\n",
      "K- 26 Validation/Test Score average (Norm):  0.5616233766233766 / 0.6\n",
      "K- 27 Validation/Test Score average (Norm):  0.558051948051948 / 0.6428571428571429\n",
      "K- 28 Validation/Test Score average (Norm):  0.5579220779220779 / 0.6142857142857143\n",
      "K- 29 Validation/Test Score average (Norm):  0.5761688311688311 / 0.6714285714285714\n",
      "Highest score mean:  0.5796753246753247 , Highest K-value:  19 \n",
      "\n",
      "p = 1\n",
      "Fold:  10\n",
      "K- 1 Validation/Test Score average (Norm):  0.5153439153439153 / 0.5571428571428572\n",
      "K- 2 Validation/Test Score average (Norm):  0.5149470899470899 / 0.5714285714285714\n",
      "K- 3 Validation/Test Score average (Norm):  0.4892857142857143 / 0.5428571428571428\n",
      "K- 4 Validation/Test Score average (Norm):  0.4859788359788359 / 0.5428571428571428\n",
      "K- 5 Validation/Test Score average (Norm):  0.5222222222222221 / 0.5714285714285714\n",
      "K- 6 Validation/Test Score average (Norm):  0.5001322751322752 / 0.5857142857142857\n",
      "K- 7 Validation/Test Score average (Norm):  0.5357142857142857 / 0.6\n",
      "K- 8 Validation/Test Score average (Norm):  0.5186507936507937 / 0.6\n",
      "K- 9 Validation/Test Score average (Norm):  0.5035714285714286 / 0.6142857142857143\n",
      "K- 10 Validation/Test Score average (Norm):  0.5112433862433863 / 0.5571428571428572\n",
      "K- 11 Validation/Test Score average (Norm):  0.4932539682539683 / 0.6142857142857143\n",
      "K- 12 Validation/Test Score average (Norm):  0.522089947089947 / 0.5571428571428572\n",
      "K- 13 Validation/Test Score average (Norm):  0.5181216931216931 / 0.5857142857142857\n",
      "K- 14 Validation/Test Score average (Norm):  0.5365079365079365 / 0.5428571428571428\n",
      "K- 15 Validation/Test Score average (Norm):  0.5403439153439153 / 0.6\n",
      "K- 16 Validation/Test Score average (Norm):  0.535978835978836 / 0.6\n",
      "K- 17 Validation/Test Score average (Norm):  0.53994708994709 / 0.5571428571428572\n",
      "K- 18 Validation/Test Score average (Norm):  0.5324074074074073 / 0.5857142857142857\n",
      "K- 19 Validation/Test Score average (Norm):  0.546957671957672 / 0.5857142857142857\n",
      "K- 20 Validation/Test Score average (Norm):  0.5505291005291004 / 0.6142857142857143\n",
      "K- 21 Validation/Test Score average (Norm):  0.5218253968253967 / 0.5714285714285714\n",
      "K- 22 Validation/Test Score average (Norm):  0.5218253968253969 / 0.6285714285714286\n",
      "K- 23 Validation/Test Score average (Norm):  0.5476190476190476 / 0.6428571428571429\n",
      "K- 24 Validation/Test Score average (Norm):  0.5326719576719576 / 0.6142857142857143\n",
      "K- 25 Validation/Test Score average (Norm):  0.5402116402116401 / 0.6\n",
      "K- 26 Validation/Test Score average (Norm):  0.5362433862433862 / 0.6\n",
      "K- 27 Validation/Test Score average (Norm):  0.522089947089947 / 0.6428571428571429\n",
      "K- 28 Validation/Test Score average (Norm):  0.5041005291005292 / 0.6142857142857143\n",
      "K- 29 Validation/Test Score average (Norm):  0.5439153439153439 / 0.6714285714285714\n",
      "Highest score mean:  0.5505291005291004 , Highest K-value:  20 \n",
      "\n",
      "p = 2\n",
      "Fold:  5\n",
      "K- 1 Validation/Test Score average (Norm):  0.49266233766233763 / 0.5714285714285714\n",
      "K- 2 Validation/Test Score average (Norm):  0.5398051948051947 / 0.6\n",
      "K- 3 Validation/Test Score average (Norm):  0.4927272727272727 / 0.5571428571428572\n",
      "K- 4 Validation/Test Score average (Norm):  0.48545454545454547 / 0.5857142857142857\n",
      "K- 5 Validation/Test Score average (Norm):  0.4855194805194805 / 0.6\n",
      "K- 6 Validation/Test Score average (Norm):  0.5143506493506493 / 0.5714285714285714\n",
      "K- 7 Validation/Test Score average (Norm):  0.4744155844155844 / 0.5571428571428572\n",
      "K- 8 Validation/Test Score average (Norm):  0.5325324675324675 / 0.5571428571428572\n",
      "K- 9 Validation/Test Score average (Norm):  0.517987012987013 / 0.5714285714285714\n",
      "K- 10 Validation/Test Score average (Norm):  0.5325324675324675 / 0.5428571428571428\n",
      "K- 11 Validation/Test Score average (Norm):  0.5288961038961038 / 0.6\n",
      "K- 12 Validation/Test Score average (Norm):  0.5541558441558442 / 0.5714285714285714\n",
      "K- 13 Validation/Test Score average (Norm):  0.5542857142857143 / 0.5571428571428572\n",
      "K- 14 Validation/Test Score average (Norm):  0.5396753246753246 / 0.5428571428571428\n",
      "K- 15 Validation/Test Score average (Norm):  0.5578571428571428 / 0.6428571428571429\n",
      "K- 16 Validation/Test Score average (Norm):  0.5688961038961039 / 0.6142857142857143\n",
      "K- 17 Validation/Test Score average (Norm):  0.5542207792207792 / 0.6285714285714286\n",
      "K- 18 Validation/Test Score average (Norm):  0.5508441558441559 / 0.6142857142857143\n",
      "K- 19 Validation/Test Score average (Norm):  0.5759740259740259 / 0.6285714285714286\n",
      "K- 20 Validation/Test Score average (Norm):  0.575974025974026 / 0.6571428571428571\n",
      "K- 21 Validation/Test Score average (Norm):  0.5542207792207792 / 0.6714285714285714\n",
      "K- 22 Validation/Test Score average (Norm):  0.5541558441558442 / 0.6571428571428571\n",
      "K- 23 Validation/Test Score average (Norm):  0.5651298701298701 / 0.6142857142857143\n",
      "K- 24 Validation/Test Score average (Norm):  0.5614935064935065 / 0.6\n",
      "K- 25 Validation/Test Score average (Norm):  0.5794805194805195 / 0.6714285714285714\n",
      "K- 26 Validation/Test Score average (Norm):  0.565064935064935 / 0.6714285714285714\n",
      "K- 27 Validation/Test Score average (Norm):  0.5616233766233766 / 0.6428571428571429\n",
      "K- 28 Validation/Test Score average (Norm):  0.5544155844155844 / 0.6285714285714286\n",
      "K- 29 Validation/Test Score average (Norm):  0.5907142857142856 / 0.6428571428571429\n",
      "Highest score mean:  0.5907142857142856 , Highest K-value:  29 \n",
      "\n",
      "p = 2\n",
      "Fold:  10\n",
      "K- 1 Validation/Test Score average (Norm):  0.5043650793650793 / 0.5714285714285714\n",
      "K- 2 Validation/Test Score average (Norm):  0.5472222222222223 / 0.6\n",
      "K- 3 Validation/Test Score average (Norm):  0.4928571428571429 / 0.5571428571428572\n",
      "K- 4 Validation/Test Score average (Norm):  0.4891534391534392 / 0.5857142857142857\n",
      "K- 5 Validation/Test Score average (Norm):  0.47817460317460314 / 0.6\n",
      "K- 6 Validation/Test Score average (Norm):  0.48915343915343906 / 0.5714285714285714\n",
      "K- 7 Validation/Test Score average (Norm):  0.4884920634920634 / 0.5571428571428572\n",
      "K- 8 Validation/Test Score average (Norm):  0.5035714285714286 / 0.5571428571428572\n",
      "K- 9 Validation/Test Score average (Norm):  0.49259259259259264 / 0.5714285714285714\n",
      "K- 10 Validation/Test Score average (Norm):  0.5105820105820106 / 0.5428571428571428\n",
      "K- 11 Validation/Test Score average (Norm):  0.49576719576719575 / 0.6\n",
      "K- 12 Validation/Test Score average (Norm):  0.5104497354497355 / 0.5714285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K- 13 Validation/Test Score average (Norm):  0.4810846560846561 / 0.5571428571428572\n",
      "K- 14 Validation/Test Score average (Norm):  0.5215608465608466 / 0.5428571428571428\n",
      "K- 15 Validation/Test Score average (Norm):  0.5027777777777778 / 0.6428571428571429\n",
      "K- 16 Validation/Test Score average (Norm):  0.5183862433862434 / 0.6142857142857143\n",
      "K- 17 Validation/Test Score average (Norm):  0.5066137566137565 / 0.6285714285714286\n",
      "K- 18 Validation/Test Score average (Norm):  0.5328042328042327 / 0.6142857142857143\n",
      "K- 19 Validation/Test Score average (Norm):  0.5181216931216931 / 0.6285714285714286\n",
      "K- 20 Validation/Test Score average (Norm):  0.5575396825396826 / 0.6571428571428571\n",
      "K- 21 Validation/Test Score average (Norm):  0.5576719576719577 / 0.6714285714285714\n",
      "K- 22 Validation/Test Score average (Norm):  0.543121693121693 / 0.6571428571428571\n",
      "K- 23 Validation/Test Score average (Norm):  0.5796296296296297 / 0.6142857142857143\n",
      "K- 24 Validation/Test Score average (Norm):  0.5505291005291004 / 0.6\n",
      "K- 25 Validation/Test Score average (Norm):  0.5796296296296297 / 0.6714285714285714\n",
      "K- 26 Validation/Test Score average (Norm):  0.5652116402116402 / 0.6714285714285714\n",
      "K- 27 Validation/Test Score average (Norm):  0.5648148148148148 / 0.6428571428571429\n",
      "K- 28 Validation/Test Score average (Norm):  0.558068783068783 / 0.6285714285714286\n",
      "K- 29 Validation/Test Score average (Norm):  0.5611111111111111 / 0.6428571428571429\n",
      "Highest score mean:  0.5796296296296297 , Highest K-value:  23 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p_value in range(1,3):    \n",
    "    for fold in [5,10]:\n",
    "        highest = 0\n",
    "        highest_k = 0\n",
    "        print('p =', p_value)\n",
    "        print('Fold: ', fold)\n",
    "        for k in range(1,30):\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors = k, p = p_value)\n",
    "            scores = cross_val_score(knn_classifier, x_train, y_train, cv = fold, scoring = 'accuracy')\n",
    "            \n",
    "            knn_classifier.fit(x_train,y_train)\n",
    "            test_predict = knn_classifier.predict(x_test)\n",
    "            \n",
    "            print('K-',k, 'Validation/Test Score average (Norm): ', scores.mean(), '/',  metrics.accuracy_score(y_test, test_predict))\n",
    "            if(scores.mean() > highest):\n",
    "                highest = scores.mean()\n",
    "                highest_k = k\n",
    "                \n",
    "        print('Highest score mean: ', highest, ', Highest K-value: ', highest_k, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7de0f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy KNN:  0.5907142857142856\n",
      "Test Accuracy KNN (Freq):  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 29, p = 2)\n",
    "scores = cross_val_score(knn_classifier, x_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "print(\"Validation Accuracy KNN: \", scores.mean())\n",
    "\n",
    "knn_classifier.fit(x_train,y_train)\n",
    "test_predict = knn_classifier.predict(x_test)\n",
    "print(\"Test Accuracy KNN (Freq): \", metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe190a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 10]\n",
      " [15 18]]\n",
      "\t\t\tKNN w Freq Dataset\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68        37\n",
      "           1       0.64      0.55      0.59        33\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.64      0.64      0.64        70\n",
      "weighted avg       0.64      0.64      0.64        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "\n",
    "# Print precision, recall and F1\n",
    "print(\"\\t\\t\\tKNN w Freq Dataset\\n\", classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-5% difference is reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705356c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab09de",
   "metadata": {},
   "source": [
    "### Norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b4f7795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 1\n",
      "Fold:  5\n",
      "K- 1 Validation/Test Score average (Norm):  0.5904545454545455 / 0.6\n",
      "\n",
      "K- 2 Validation/Test Score average (Norm):  0.5505194805194804 / 0.5571428571428572\n",
      "\n",
      "K- 3 Validation/Test Score average (Norm):  0.546948051948052 / 0.5857142857142857\n",
      "\n",
      "K- 4 Validation/Test Score average (Norm):  0.5324025974025973 / 0.5714285714285714\n",
      "\n",
      "K- 5 Validation/Test Score average (Norm):  0.5143506493506493 / 0.5571428571428572\n",
      "\n",
      "K- 6 Validation/Test Score average (Norm):  0.5216883116883116 / 0.5714285714285714\n",
      "\n",
      "K- 7 Validation/Test Score average (Norm):  0.5324025974025974 / 0.5857142857142857\n",
      "\n",
      "K- 8 Validation/Test Score average (Norm):  0.5468181818181819 / 0.6\n",
      "\n",
      "K- 9 Validation/Test Score average (Norm):  0.5433116883116883 / 0.5571428571428572\n",
      "\n",
      "K- 10 Validation/Test Score average (Norm):  0.5614285714285714 / 0.5571428571428572\n",
      "\n",
      "K- 11 Validation/Test Score average (Norm):  0.5431818181818182 / 0.6\n",
      "\n",
      "K- 12 Validation/Test Score average (Norm):  0.5468831168831169 / 0.5428571428571428\n",
      "\n",
      "K- 13 Validation/Test Score average (Norm):  0.546948051948052 / 0.6142857142857143\n",
      "\n",
      "K- 14 Validation/Test Score average (Norm):  0.5612987012987013 / 0.5285714285714286\n",
      "\n",
      "K- 15 Validation/Test Score average (Norm):  0.535974025974026 / 0.5571428571428572\n",
      "\n",
      "K- 16 Validation/Test Score average (Norm):  0.5395454545454546 / 0.5285714285714286\n",
      "\n",
      "K- 17 Validation/Test Score average (Norm):  0.5397402597402597 / 0.6\n",
      "\n",
      "K- 18 Validation/Test Score average (Norm):  0.5178571428571429 / 0.5857142857142857\n",
      "\n",
      "K- 19 Validation/Test Score average (Norm):  0.5143506493506493 / 0.6142857142857143\n",
      "\n",
      "K- 20 Validation/Test Score average (Norm):  0.5287012987012987 / 0.5714285714285714\n",
      "\n",
      "K- 21 Validation/Test Score average (Norm):  0.5323376623376623 / 0.5857142857142857\n",
      "\n",
      "K- 22 Validation/Test Score average (Norm):  0.5248701298701299 / 0.5857142857142857\n",
      "\n",
      "K- 23 Validation/Test Score average (Norm):  0.5359740259740259 / 0.6\n",
      "\n",
      "K- 24 Validation/Test Score average (Norm):  0.5503246753246753 / 0.6428571428571429\n",
      "\n",
      "K- 25 Validation/Test Score average (Norm):  0.5505194805194805 / 0.6285714285714286\n",
      "\n",
      "K- 26 Validation/Test Score average (Norm):  0.5361038961038961 / 0.6285714285714286\n",
      "\n",
      "K- 27 Validation/Test Score average (Norm):  0.5613636363636363 / 0.6428571428571429\n",
      "\n",
      "K- 28 Validation/Test Score average (Norm):  0.5434415584415585 / 0.6285714285714286\n",
      "\n",
      "K- 29 Validation/Test Score average (Norm):  0.5544155844155844 / 0.6428571428571429\n",
      "\n",
      "Highest score mean:  0.5904545454545455 , Highest K-value:  1 \n",
      "\n",
      "p = 1\n",
      "Fold:  10\n",
      "K- 1 Validation/Test Score average (Norm):  0.5575396825396826 / 0.6\n",
      "\n",
      "K- 2 Validation/Test Score average (Norm):  0.553968253968254 / 0.5571428571428572\n",
      "\n",
      "K- 3 Validation/Test Score average (Norm):  0.5041005291005292 / 0.5857142857142857\n",
      "\n",
      "K- 4 Validation/Test Score average (Norm):  0.5396825396825397 / 0.5714285714285714\n",
      "\n",
      "K- 5 Validation/Test Score average (Norm):  0.5005291005291005 / 0.5571428571428572\n",
      "\n",
      "K- 6 Validation/Test Score average (Norm):  0.5220899470899469 / 0.5714285714285714\n",
      "\n",
      "K- 7 Validation/Test Score average (Norm):  0.5006613756613757 / 0.5857142857142857\n",
      "\n",
      "K- 8 Validation/Test Score average (Norm):  0.5296296296296297 / 0.6\n",
      "\n",
      "K- 9 Validation/Test Score average (Norm):  0.532936507936508 / 0.5571428571428572\n",
      "\n",
      "K- 10 Validation/Test Score average (Norm):  0.5473544973544973 / 0.5571428571428572\n",
      "\n",
      "K- 11 Validation/Test Score average (Norm):  0.5439153439153439 / 0.6\n",
      "\n",
      "K- 12 Validation/Test Score average (Norm):  0.5398148148148147 / 0.5428571428571428\n",
      "\n",
      "K- 13 Validation/Test Score average (Norm):  0.528968253968254 / 0.6142857142857143\n",
      "\n",
      "K- 14 Validation/Test Score average (Norm):  0.5326719576719576 / 0.5285714285714286\n",
      "\n",
      "K- 15 Validation/Test Score average (Norm):  0.5437830687830688 / 0.5571428571428572\n",
      "\n",
      "K- 16 Validation/Test Score average (Norm):  0.5398148148148147 / 0.5285714285714286\n",
      "\n",
      "K- 17 Validation/Test Score average (Norm):  0.5367724867724868 / 0.6\n",
      "\n",
      "K- 18 Validation/Test Score average (Norm):  0.5112433862433863 / 0.5857142857142857\n",
      "\n",
      "K- 19 Validation/Test Score average (Norm):  0.5115079365079366 / 0.6142857142857143\n",
      "\n",
      "K- 20 Validation/Test Score average (Norm):  0.5005291005291006 / 0.5714285714285714\n",
      "\n",
      "K- 21 Validation/Test Score average (Norm):  0.5148148148148148 / 0.5857142857142857\n",
      "\n",
      "K- 22 Validation/Test Score average (Norm):  0.503968253968254 / 0.5857142857142857\n",
      "\n",
      "K- 23 Validation/Test Score average (Norm):  0.5072751322751323 / 0.6\n",
      "\n",
      "K- 24 Validation/Test Score average (Norm):  0.5108465608465609 / 0.6428571428571429\n",
      "\n",
      "K- 25 Validation/Test Score average (Norm):  0.5398148148148147 / 0.6285714285714286\n",
      "\n",
      "K- 26 Validation/Test Score average (Norm):  0.5297619047619047 / 0.6285714285714286\n",
      "\n",
      "K- 27 Validation/Test Score average (Norm):  0.5476190476190477 / 0.6428571428571429\n",
      "\n",
      "K- 28 Validation/Test Score average (Norm):  0.5585978835978838 / 0.6285714285714286\n",
      "\n",
      "K- 29 Validation/Test Score average (Norm):  0.5404761904761904 / 0.6428571428571429\n",
      "\n",
      "Highest score mean:  0.5585978835978838 , Highest K-value:  28 \n",
      "\n",
      "p = 2\n",
      "Fold:  5\n",
      "K- 1 Validation/Test Score average (Norm):  0.5688311688311687 / 0.5857142857142857\n",
      "\n",
      "K- 2 Validation/Test Score average (Norm):  0.5505844155844156 / 0.5428571428571428\n",
      "\n",
      "K- 3 Validation/Test Score average (Norm):  0.5397402597402596 / 0.6\n",
      "\n",
      "K- 4 Validation/Test Score average (Norm):  0.5397402597402596 / 0.6142857142857143\n",
      "\n",
      "K- 5 Validation/Test Score average (Norm):  0.49993506493506495 / 0.5857142857142857\n",
      "\n",
      "K- 6 Validation/Test Score average (Norm):  0.5578571428571429 / 0.5428571428571428\n",
      "\n",
      "K- 7 Validation/Test Score average (Norm):  0.5398701298701298 / 0.5\n",
      "\n",
      "K- 8 Validation/Test Score average (Norm):  0.5577272727272727 / 0.5428571428571428\n",
      "\n",
      "K- 9 Validation/Test Score average (Norm):  0.5360389610389611 / 0.5285714285714286\n",
      "\n",
      "K- 10 Validation/Test Score average (Norm):  0.5467532467532467 / 0.5714285714285714\n",
      "\n",
      "K- 11 Validation/Test Score average (Norm):  0.5322727272727272 / 0.5285714285714286\n",
      "\n",
      "K- 12 Validation/Test Score average (Norm):  0.5287012987012987 / 0.5714285714285714\n",
      "\n",
      "K- 13 Validation/Test Score average (Norm):  0.5359090909090909 / 0.6\n",
      "\n",
      "K- 14 Validation/Test Score average (Norm):  0.5467532467532468 / 0.5428571428571428\n",
      "\n",
      "K- 15 Validation/Test Score average (Norm):  0.5466883116883116 / 0.5285714285714286\n",
      "\n",
      "K- 16 Validation/Test Score average (Norm):  0.5395454545454546 / 0.5428571428571428\n",
      "\n",
      "K- 17 Validation/Test Score average (Norm):  0.5325324675324675 / 0.6\n",
      "\n",
      "K- 18 Validation/Test Score average (Norm):  0.5395454545454544 / 0.5571428571428572\n",
      "\n",
      "K- 19 Validation/Test Score average (Norm):  0.5651298701298701 / 0.6142857142857143\n",
      "\n",
      "K- 20 Validation/Test Score average (Norm):  0.5868181818181818 / 0.6142857142857143\n",
      "\n",
      "K- 21 Validation/Test Score average (Norm):  0.5653896103896103 / 0.6285714285714286\n",
      "\n",
      "K- 22 Validation/Test Score average (Norm):  0.5615584415584415 / 0.6142857142857143\n",
      "\n",
      "K- 23 Validation/Test Score average (Norm):  0.5725324675324674 / 0.6428571428571429\n",
      "\n",
      "K- 24 Validation/Test Score average (Norm):  0.5687662337662337 / 0.6428571428571429\n",
      "\n",
      "K- 25 Validation/Test Score average (Norm):  0.5760389610389611 / 0.6714285714285714\n",
      "\n",
      "K- 26 Validation/Test Score average (Norm):  0.5832467532467532 / 0.6714285714285714\n",
      "\n",
      "K- 27 Validation/Test Score average (Norm):  0.5942207792207792 / 0.6571428571428571\n",
      "\n",
      "K- 28 Validation/Test Score average (Norm):  0.5833766233766233 / 0.6285714285714286\n",
      "\n",
      "K- 29 Validation/Test Score average (Norm):  0.5833116883116884 / 0.6714285714285714\n",
      "\n",
      "Highest score mean:  0.5942207792207792 , Highest K-value:  27 \n",
      "\n",
      "p = 2\n",
      "Fold:  10\n",
      "K- 1 Validation/Test Score average (Norm):  0.5466931216931217 / 0.5857142857142857\n",
      "\n",
      "K- 2 Validation/Test Score average (Norm):  0.5361111111111111 / 0.5428571428571428\n",
      "\n",
      "K- 3 Validation/Test Score average (Norm):  0.5216931216931218 / 0.6\n",
      "\n",
      "K- 4 Validation/Test Score average (Norm):  0.5395502645502644 / 0.6142857142857143\n",
      "\n",
      "K- 5 Validation/Test Score average (Norm):  0.5037037037037038 / 0.5857142857142857\n",
      "\n",
      "K- 6 Validation/Test Score average (Norm):  0.5248677248677248 / 0.5428571428571428\n",
      "\n",
      "K- 7 Validation/Test Score average (Norm):  0.5321428571428571 / 0.5\n",
      "\n",
      "K- 8 Validation/Test Score average (Norm):  0.5505291005291005 / 0.5428571428571428\n",
      "\n",
      "K- 9 Validation/Test Score average (Norm):  0.5612433862433862 / 0.5285714285714286\n",
      "\n",
      "K- 10 Validation/Test Score average (Norm):  0.554100529100529 / 0.5714285714285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K- 11 Validation/Test Score average (Norm):  0.5502645502645501 / 0.5285714285714286\n",
      "\n",
      "K- 12 Validation/Test Score average (Norm):  0.5247354497354497 / 0.5714285714285714\n",
      "\n",
      "K- 13 Validation/Test Score average (Norm):  0.538888888888889 / 0.6\n",
      "\n",
      "K- 14 Validation/Test Score average (Norm):  0.5173280423280424 / 0.5428571428571428\n",
      "\n",
      "K- 15 Validation/Test Score average (Norm):  0.5281746031746033 / 0.5285714285714286\n",
      "\n",
      "K- 16 Validation/Test Score average (Norm):  0.5429894179894179 / 0.5428571428571428\n",
      "\n",
      "K- 17 Validation/Test Score average (Norm):  0.5394179894179894 / 0.6\n",
      "\n",
      "K- 18 Validation/Test Score average (Norm):  0.5359788359788359 / 0.5571428571428572\n",
      "\n",
      "K- 19 Validation/Test Score average (Norm):  0.5395502645502646 / 0.6142857142857143\n",
      "\n",
      "K- 20 Validation/Test Score average (Norm):  0.5617724867724868 / 0.6142857142857143\n",
      "\n",
      "K- 21 Validation/Test Score average (Norm):  0.5547619047619048 / 0.6285714285714286\n",
      "\n",
      "K- 22 Validation/Test Score average (Norm):  0.5441798941798942 / 0.6142857142857143\n",
      "\n",
      "K- 23 Validation/Test Score average (Norm):  0.5583333333333333 / 0.6428571428571429\n",
      "\n",
      "K- 24 Validation/Test Score average (Norm):  0.5515873015873016 / 0.6428571428571429\n",
      "\n",
      "K- 25 Validation/Test Score average (Norm):  0.5550264550264551 / 0.6714285714285714\n",
      "\n",
      "K- 26 Validation/Test Score average (Norm):  0.5439153439153439 / 0.6714285714285714\n",
      "\n",
      "K- 27 Validation/Test Score average (Norm):  0.5584656084656084 / 0.6571428571428571\n",
      "\n",
      "K- 28 Validation/Test Score average (Norm):  0.55489417989418 / 0.6285714285714286\n",
      "\n",
      "K- 29 Validation/Test Score average (Norm):  0.5506613756613756 / 0.6714285714285714\n",
      "\n",
      "Highest score mean:  0.5617724867724868 , Highest K-value:  20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p_value in range(1,3):\n",
    "    \n",
    "    for fold in [5,10]:\n",
    "        highest = 0\n",
    "        highest_k = 0\n",
    "        print('p =', p_value)\n",
    "        print('Fold: ', fold)\n",
    "        for k in range(1,30):\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors = k, p = p_value)\n",
    "            scores = cross_val_score(knn_classifier, x_train, y_train, cv = fold, scoring = 'accuracy')\n",
    "            \n",
    "            knn_classifier.fit(x_train,y_train)\n",
    "            test_predict = knn_classifier.predict(x_test)\n",
    "            \n",
    "            print('K-',k, 'Validation/Test Score average (Norm): ', scores.mean(), '/',  metrics.accuracy_score(y_test, test_predict))\n",
    "            if(scores.mean() > highest):\n",
    "                highest = scores.mean()\n",
    "                highest_k = k\n",
    "            print()\n",
    "        print('Highest score mean: ', highest, ', Highest K-value: ', highest_k, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7baaed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy KNN:  0.5616233766233766\n",
      "Test Accuracy KNN (Norm):  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 27, p = 2)\n",
    "scores = cross_val_score(knn_classifier, x_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "print(\"Validation Accuracy KNN: \", scores.mean())\n",
    "\n",
    "knn_classifier.fit(x_train,y_train)\n",
    "test_predict = knn_classifier.predict(x_test)\n",
    "print(\"Test Accuracy KNN (Norm): \", metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13374796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 10]\n",
      " [15 18]]\n",
      "\t\t\tKNN w Freq Dataset\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68        37\n",
      "           1       0.64      0.55      0.59        33\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.64      0.64      0.64        70\n",
      "weighted avg       0.64      0.64      0.64        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "\n",
    "# Print precision, recall and F1\n",
    "print(\"\\t\\t\\tKNN w Freq Dataset\\n\", classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7dc401",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c10a19",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "070640ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4098d8b",
   "metadata": {},
   "source": [
    "### Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d97a3c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel= linear\n",
      "Fold=  5\n",
      "C=  1.0 \n",
      "Validation score for SVM linear :  0.5795454545454545\n",
      "Testing score for SVM RBF (Freq):  0.6285714285714286 \n",
      "\n",
      "Kernel= linear\n",
      "Fold=  10\n",
      "C=  1.0 \n",
      "Validation score for SVM linear :  0.5698412698412698\n",
      "Testing score for SVM RBF (Freq):  0.6285714285714286 \n",
      "\n",
      "Kernel= poly\n",
      "Fold=  5\n",
      "C=  100.0 \n",
      "Validation score for SVM poly :  0.5763636363636364\n",
      "Testing score for SVM RBF (Freq):  0.5714285714285714 \n",
      "\n",
      "Kernel= poly\n",
      "Fold=  10\n",
      "C=  1.0 \n",
      "Validation score for SVM poly :  0.5834656084656084\n",
      "Testing score for SVM RBF (Freq):  0.5142857142857142 \n",
      "\n",
      "Kernel= rbf\n",
      "Fold=  5\n",
      "C=  1.0 \n",
      "Validation score for SVM rbf :  0.5759090909090909\n",
      "Testing score for SVM RBF (Freq):  0.6428571428571429 \n",
      "\n",
      "Kernel= rbf\n",
      "Fold=  10\n",
      "C=  1.0 \n",
      "Validation score for SVM rbf :  0.5838624338624337\n",
      "Testing score for SVM RBF (Freq):  0.6428571428571429 \n",
      "\n",
      "Kernel= sigmoid\n",
      "Fold=  5\n",
      "C=  10.0 \n",
      "Validation score for SVM sigmoid :  0.5577272727272726\n",
      "Testing score for SVM RBF (Freq):  0.5714285714285714 \n",
      "\n",
      "Kernel= sigmoid\n",
      "Fold=  10\n",
      "C=  10.0 \n",
      "Validation score for SVM sigmoid :  0.5362433862433863\n",
      "Testing score for SVM RBF (Freq):  0.5714285714285714 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1.0,10.0,100.0,1000.0]}\n",
    "for SVM_mode in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for fold in [5,10]:\n",
    "        grid_search = GridSearchCV(SVC(kernel= SVM_mode), param_grid, cv= fold)\n",
    "        grid_result = grid_search.fit(x_train, y_train)\n",
    "        C_best = grid_result.best_params_.get('C') #{'C' : '1'}\n",
    "        print('Kernel=', SVM_mode)\n",
    "        print('Fold= ', fold)\n",
    "        \n",
    "        if(SVM_mode == 'linear'):\n",
    "            svm = SVC(kernel= SVM_mode, C= C_best)\n",
    "        else:\n",
    "            svm = SVC(kernel= SVM_mode, C= C_best, gamma= 'scale')\n",
    "        \n",
    "        scores = cross_val_score(svm, x_train, y_train, cv= fold, scoring = 'accuracy')\n",
    "        print('C= ',C_best, '\\nValidation score for SVM', SVM_mode, ': ', scores.mean())\n",
    "        \n",
    "        svm.fit(x_train,y_train)\n",
    "        test_predict = svm.predict(x_test)\n",
    "        print(\"Testing score for SVM RBF (Freq): \", metrics.accuracy_score(y_test, test_predict),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7246857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for SVM RBF (Freq):  0.5838624338624337\n",
      "Testing score for SVM RBF (Freq):  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "SVM_mode = 'rbf'\n",
    "C_value = 1\n",
    "\n",
    "svm = SVC(kernel= SVM_mode, C= C_value)\n",
    "scores = cross_val_score(svm, x_train, y_train, cv= 10, scoring = 'accuracy')\n",
    "print('Validation score for SVM RBF (Freq): ', scores.mean())\n",
    "\n",
    "svm.fit(x_train,y_train)\n",
    "test_predict = svm.predict(x_test)\n",
    "print(\"Testing score for SVM RBF (Freq): \", metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "914d277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  5]\n",
      " [20 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72        37\n",
      "           1       0.72      0.39      0.51        33\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.67      0.63      0.61        70\n",
      "weighted avg       0.67      0.64      0.62        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "# Print precision, recall and F1\n",
    "print(classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb555de",
   "metadata": {},
   "source": [
    "### Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9354e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel= linear\n",
      "Fold=  5\n",
      "C=  1.0 \n",
      "Validation score for SVM linear :  0.5577922077922077\n",
      "Testing score for SVM RBF (Norm):  0.6714285714285714 \n",
      "\n",
      "Kernel= linear\n",
      "Fold=  10\n",
      "C=  1.0 \n",
      "Validation score for SVM linear :  0.5443121693121693\n",
      "Testing score for SVM RBF (Norm):  0.6714285714285714 \n",
      "\n",
      "Kernel= poly\n",
      "Fold=  5\n",
      "C=  1.0 \n",
      "Validation score for SVM poly :  0.615844155844156\n",
      "Testing score for SVM RBF (Norm):  0.6857142857142857 \n",
      "\n",
      "Kernel= poly\n",
      "Fold=  10\n",
      "C=  1.0 \n",
      "Validation score for SVM poly :  0.6236772486772486\n",
      "Testing score for SVM RBF (Norm):  0.6857142857142857 \n",
      "\n",
      "Kernel= rbf\n",
      "Fold=  5\n",
      "C=  1.0 \n",
      "Validation score for SVM rbf :  0.5976623376623376\n",
      "Testing score for SVM RBF (Norm):  0.6571428571428571 \n",
      "\n",
      "Kernel= rbf\n",
      "Fold=  10\n",
      "C=  10.0 \n",
      "Validation score for SVM rbf :  0.6091269841269841\n",
      "Testing score for SVM RBF (Norm):  0.6142857142857143 \n",
      "\n",
      "Kernel= sigmoid\n",
      "Fold=  5\n",
      "C=  1.0 \n",
      "Validation score for SVM sigmoid :  0.507077922077922\n",
      "Testing score for SVM RBF (Norm):  0.5142857142857142 \n",
      "\n",
      "Kernel= sigmoid\n",
      "Fold=  10\n",
      "C=  1.0 \n",
      "Validation score for SVM sigmoid :  0.5144179894179894\n",
      "Testing score for SVM RBF (Norm):  0.5142857142857142 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1.0,10.0,100.0,1000.0]}\n",
    "for SVM_mode in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for fold in [5,10]:\n",
    "        grid_search = GridSearchCV(SVC(kernel= SVM_mode), param_grid, cv= fold)\n",
    "        grid_result = grid_search.fit(x_train, y_train)\n",
    "        C_best = grid_result.best_params_.get('C') #{'C' : '1'}\n",
    "        print('Kernel=', SVM_mode)\n",
    "        print('Fold= ', fold)\n",
    "        \n",
    "        if(SVM_mode == 'linear'):\n",
    "            svm = SVC(kernel= SVM_mode, C= C_best)\n",
    "        else:\n",
    "            svm = SVC(kernel= SVM_mode, C= C_best, gamma= 'scale')\n",
    "        \n",
    "        scores = cross_val_score(svm, x_train, y_train, cv= fold, scoring = 'accuracy')\n",
    "        print('C= ',C_best, '\\nValidation score for SVM', SVM_mode, ': ', scores.mean())                \n",
    "        svm.fit(x_train,y_train)\n",
    "        test_predict = svm.predict(x_test)\n",
    "        print(\"Testing score for SVM RBF (Norm): \", metrics.accuracy_score(y_test, test_predict),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35ff13f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for SVM poly : 0.6236772486772486\n",
      "Testing score for SVM poly (Norm): 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "SVM_mode = 'poly'\n",
    "C_value = 1\n",
    "\n",
    "svm = SVC(kernel= SVM_mode, C= C_value)\n",
    "scores = cross_val_score(svm, x_train, y_train, cv= 10, scoring = 'accuracy')\n",
    "print('Validation score for SVM', SVM_mode, ':', scores.mean())\n",
    "\n",
    "svm.fit(x_train,y_train)\n",
    "test_predict = svm.predict(x_test)\n",
    "print('Testing score for SVM', SVM_mode, '(Norm):', metrics.accuracy_score(y_test, test_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b482fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26 11]\n",
      " [11 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        37\n",
      "           1       0.67      0.67      0.67        33\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.68      0.68      0.68        70\n",
      "weighted avg       0.69      0.69      0.69        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "# Print precision, recall and F1\n",
    "print(classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacb9b7",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bfe130",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7575a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37366e95",
   "metadata": {},
   "source": [
    "### Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c679deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq Naive Bayes\n",
      "\n",
      "At fold 5 , using GaussianNB()\n",
      "\tValidation accuracy score (Freq): 0.5688961038961039\n",
      "\tTesting score (Freq): 0.5857142857142857\n",
      "At fold 10 , using GaussianNB()\n",
      "\tValidation accuracy score (Freq): 0.5838624338624339\n",
      "\tTesting score (Freq): 0.5857142857142857\n",
      "\n",
      "\n",
      "At fold 5 , using BernoulliNB()\n",
      "\tValidation accuracy score (Freq): 0.5544805194805195\n",
      "\tTesting score (Freq): 0.6571428571428571\n",
      "At fold 10 , using BernoulliNB()\n",
      "\tValidation accuracy score (Freq): 0.5474867724867725\n",
      "\tTesting score (Freq): 0.6571428571428571\n",
      "\n",
      "\n",
      "At fold 5 , using MultinomialNB()\n",
      "\tValidation accuracy score (Freq): 0.5761688311688311\n",
      "\tTesting score (Freq): 0.6857142857142857\n",
      "At fold 10 , using MultinomialNB()\n",
      "\tValidation accuracy score (Freq): 0.5693121693121693\n",
      "\tTesting score (Freq): 0.6857142857142857\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Freq Naive Bayes\\n')\n",
    "\n",
    "for NB in [GaussianNB(), BernoulliNB(), MultinomialNB()]:\n",
    "    for fold in [5,10]:\n",
    "        print('At fold',fold, ', using', NB)\n",
    "        scores= cross_val_score(NB, x_train, y_train, cv= fold, scoring= 'accuracy')\n",
    "        print('\\tValidation accuracy score (Freq):',scores.mean())\n",
    "        \n",
    "        NB.fit(x_train,y_train)\n",
    "        test_predict= NB.predict(x_test)\n",
    "        print('\\tTesting score (Freq):', metrics.accuracy_score(y_test, test_predict))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22567178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for GaussianNB() : 0.5838624338624339\n",
      "Testing score (Freq): 0.5857142857142857\n"
     ]
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "scores = cross_val_score(NB, x_train, y_train, cv= 10, scoring = 'accuracy')\n",
    "print('Validation score for', NB, ':', scores.mean())\n",
    "\n",
    "NB.fit(x_train,y_train)\n",
    "test_predict= NB.predict(x_test)\n",
    "print('Testing score (Freq):', metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "876064b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  7]\n",
      " [22 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.81      0.67        37\n",
      "           1       0.61      0.33      0.43        33\n",
      "\n",
      "    accuracy                           0.59        70\n",
      "   macro avg       0.59      0.57      0.55        70\n",
      "weighted avg       0.59      0.59      0.56        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "# Print precision, recall and F1\n",
    "print(classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fcd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7022789",
   "metadata": {},
   "source": [
    "### Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0274f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm Naive Bayes\n",
      "\n",
      "At fold 5 , using GaussianNB()\n",
      "\tValidation accuracy score (Norm): 0.5653246753246753\n",
      "\tTesting score (Norm): 0.6714285714285714\n",
      "At fold 10 , using GaussianNB()\n",
      "\tValidation accuracy score (Norm): 0.5763227513227513\n",
      "\tTesting score (Norm): 0.6714285714285714\n",
      "\n",
      "\n",
      "At fold 5 , using BernoulliNB()\n",
      "\tValidation accuracy score (Norm): 0.5580519480519481\n",
      "\tTesting score (Norm): 0.6571428571428571\n",
      "At fold 10 , using BernoulliNB()\n",
      "\tValidation accuracy score (Norm): 0.543915343915344\n",
      "\tTesting score (Norm): 0.6571428571428571\n",
      "\n",
      "\n",
      "At fold 5 , using MultinomialNB()\n",
      "\tValidation accuracy score (Norm): 0.5978571428571429\n",
      "\tTesting score (Norm): 0.6285714285714286\n",
      "At fold 10 , using MultinomialNB()\n",
      "\tValidation accuracy score (Norm): 0.6022486772486773\n",
      "\tTesting score (Norm): 0.6285714285714286\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Norm Naive Bayes\\n')\n",
    "\n",
    "for NB in [GaussianNB(), BernoulliNB(), MultinomialNB()]:\n",
    "    for fold in [5,10]:\n",
    "        print('At fold',fold, ', using', NB)\n",
    "        scores= cross_val_score(NB, x_train, y_train, cv= fold, scoring= 'accuracy')\n",
    "        print('\\tValidation accuracy score (Norm):',scores.mean())\n",
    "        \n",
    "        NB.fit(x_train,y_train)\n",
    "        test_predict= NB.predict(x_test)\n",
    "        print('\\tTesting score (Norm):', metrics.accuracy_score(y_test, test_predict))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9227285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for MultinomialNB() : 0.6022486772486773\n",
      "Testing score (Freq): 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "scores = cross_val_score(NB, x_train, y_train, cv= 10, scoring = 'accuracy')\n",
    "print('Validation score for', NB, ':', scores.mean())\n",
    "\n",
    "NB.fit(x_train,y_train)\n",
    "test_predict= NB.predict(x_test)\n",
    "print('Testing score (Freq):', metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "40e80380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26 11]\n",
      " [15 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.67        37\n",
      "           1       0.62      0.55      0.58        33\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.63      0.62      0.62        70\n",
      "weighted avg       0.63      0.63      0.63        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "# Print precision, recall and F1\n",
    "print(classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef1aec",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1a103",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c96bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5d7e1",
   "metadata": {},
   "source": [
    "### Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d80929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At fold 5 , using criterion gini at max_depth 1\n",
      "\tValidation/Testing score (Freq): 0.5470129870129871 / 0.5571428571428572 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 1\n",
      "\tValidation/Testing score (Freq): 0.5398148148148149 / 0.5571428571428572 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 2\n",
      "\tValidation/Testing score (Freq): 0.5471428571428572 / 0.5714285714285714 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 2\n",
      "\tValidation/Testing score (Freq): 0.5757936507936509 / 0.5714285714285714 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 3\n",
      "\tValidation/Testing score (Freq): 0.5616233766233766 / 0.5714285714285714 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 3\n",
      "\tValidation/Testing score (Freq): 0.5657407407407408 / 0.5714285714285714 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 4\n",
      "\tValidation/Testing score (Freq): 0.576038961038961 / 0.5142857142857142 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 4\n",
      "\tValidation/Testing score (Freq): 0.5469576719576719 / 0.5142857142857142 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 5\n",
      "\tValidation/Testing score (Freq): 0.583116883116883 / 0.5 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 5\n",
      "\tValidation/Testing score (Freq): 0.5615079365079365 / 0.5 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 1\n",
      "\tValidation/Testing score (Freq): 0.5361038961038961 / 0.5571428571428572 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 1\n",
      "\tValidation/Testing score (Freq): 0.5398148148148149 / 0.5571428571428572 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 2\n",
      "\tValidation/Testing score (Freq): 0.528961038961039 / 0.5714285714285714 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 2\n",
      "\tValidation/Testing score (Freq): 0.5576719576719577 / 0.5714285714285714 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 3\n",
      "\tValidation/Testing score (Freq): 0.5507142857142857 / 0.5714285714285714 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 3\n",
      "\tValidation/Testing score (Freq): 0.5722222222222222 / 0.5714285714285714 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 4\n",
      "\tValidation/Testing score (Freq): 0.5395454545454546 / 0.5857142857142857 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 4\n",
      "\tValidation/Testing score (Freq): 0.546957671957672 / 0.5857142857142857 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 5\n",
      "\tValidation/Testing score (Freq): 0.5322727272727272 / 0.4857142857142857 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 5\n",
      "\tValidation/Testing score (Freq): 0.5365079365079365 / 0.4857142857142857 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dtree_criterion in [\"gini\", \"entropy\"]:\n",
    "    for dtree_max_depth in range(1,6):\n",
    "        for fold in [5, 10]:\n",
    "            dtree = DecisionTreeClassifier(criterion = dtree_criterion, max_depth = dtree_max_depth)\n",
    "            print('At fold',fold, ', using criterion', dtree_criterion, 'at max_depth', dtree_max_depth)\n",
    "            scores= cross_val_score(dtree, x_train, y_train, cv= fold, scoring= 'accuracy')\n",
    "            \n",
    "            dtree.fit(x_train, y_train)\n",
    "            test_predict = dtree.predict(x_test)\n",
    "            dtree = DecisionTreeClassifier(criterion = dtree_criterion, max_depth = dtree_max_depth)\n",
    "            print('\\tValidation/Testing score (Freq):', scores.mean(),'/', metrics.accuracy_score(y_test, test_predict), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7467f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy score (Freq): 0.5757936507936509\n",
      "Testing score (Freq): 0.5714285714285714 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_criterion = 'gini'\n",
    "dtree_max_depth = 2\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion = dtree_criterion, max_depth = dtree_max_depth)\n",
    "\n",
    "\n",
    "scores= cross_val_score(dtree, x_train, y_train, cv= fold, scoring= 'accuracy')\n",
    "print('Validation accuracy score (Freq):',scores.mean())\n",
    "\n",
    "dtree.fit(x_train, y_train)\n",
    "test_predict = dtree.predict(x_test)\n",
    "print('Testing score (Freq):', metrics.accuracy_score(y_test, test_predict), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b15fc58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  7]\n",
      " [23 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.81      0.67        37\n",
      "           1       0.59      0.30      0.40        33\n",
      "\n",
      "    accuracy                           0.57        70\n",
      "   macro avg       0.58      0.56      0.53        70\n",
      "weighted avg       0.58      0.57      0.54        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "# Print precision, recall and F1\n",
    "print(classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e74c10",
   "metadata": {},
   "source": [
    "### Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddb3359e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At fold 5 , using criterion gini at max_depth 1\n",
      "\tValidation accuracy score (Norm): 0.5253246753246753\n",
      "\tTesting score (Norm): 0.5571428571428572 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 1\n",
      "\tValidation accuracy score (Norm): 0.5326719576719576\n",
      "\tTesting score (Norm): 0.5571428571428572 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 2\n",
      "\tValidation accuracy score (Norm): 0.5722077922077922\n",
      "\tTesting score (Norm): 0.6 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 2\n",
      "\tValidation accuracy score (Norm): 0.5834656084656085\n",
      "\tTesting score (Norm): 0.6 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 3\n",
      "\tValidation accuracy score (Norm): 0.5540259740259741\n",
      "\tTesting score (Norm): 0.6142857142857143 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 3\n",
      "\tValidation accuracy score (Norm): 0.5543650793650794\n",
      "\tTesting score (Norm): 0.6142857142857143 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 4\n",
      "\tValidation accuracy score (Norm): 0.5431818181818182\n",
      "\tTesting score (Norm): 0.5428571428571428 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 4\n",
      "\tValidation accuracy score (Norm): 0.5070105820105819\n",
      "\tTesting score (Norm): 0.5428571428571428 \n",
      "\n",
      "At fold 5 , using criterion gini at max_depth 5\n",
      "\tValidation accuracy score (Norm): 0.528961038961039\n",
      "\tTesting score (Norm): 0.5285714285714286 \n",
      "\n",
      "At fold 10 , using criterion gini at max_depth 5\n",
      "\tValidation accuracy score (Norm): 0.5615079365079365\n",
      "\tTesting score (Norm): 0.5285714285714286 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 1\n",
      "\tValidation accuracy score (Norm): 0.5362337662337662\n",
      "\tTesting score (Norm): 0.5285714285714286 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 1\n",
      "\tValidation accuracy score (Norm): 0.5326719576719576\n",
      "\tTesting score (Norm): 0.5285714285714286 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 2\n",
      "\tValidation accuracy score (Norm): 0.5722077922077922\n",
      "\tTesting score (Norm): 0.5714285714285714 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 2\n",
      "\tValidation accuracy score (Norm): 0.5583333333333333\n",
      "\tTesting score (Norm): 0.5714285714285714 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 3\n",
      "\tValidation accuracy score (Norm): 0.5326623376623376\n",
      "\tTesting score (Norm): 0.5714285714285714 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 3\n",
      "\tValidation accuracy score (Norm): 0.5476190476190477\n",
      "\tTesting score (Norm): 0.5714285714285714 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 4\n",
      "\tValidation accuracy score (Norm): 0.5579220779220779\n",
      "\tTesting score (Norm): 0.6 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 4\n",
      "\tValidation accuracy score (Norm): 0.5691798941798941\n",
      "\tTesting score (Norm): 0.6 \n",
      "\n",
      "At fold 5 , using criterion entropy at max_depth 5\n",
      "\tValidation accuracy score (Norm): 0.5324675324675325\n",
      "\tTesting score (Norm): 0.5857142857142857 \n",
      "\n",
      "At fold 10 , using criterion entropy at max_depth 5\n",
      "\tValidation accuracy score (Norm): 0.5145502645502645\n",
      "\tTesting score (Norm): 0.5857142857142857 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dtree_criterion in [\"gini\", \"entropy\"]:\n",
    "    for dtree_max_depth in range(1,6):\n",
    "        for fold in [5, 10]:\n",
    "            dtree = DecisionTreeClassifier(criterion = dtree_criterion, max_depth = dtree_max_depth)\n",
    "            print('At fold',fold, ', using criterion', dtree_criterion, 'at max_depth', dtree_max_depth)\n",
    "            scores= cross_val_score(dtree, x_train, y_train, cv= fold, scoring= 'accuracy')\n",
    "            print('\\tValidation accuracy score (Norm):',scores.mean())\n",
    "            \n",
    "            dtree.fit(x_train, y_train)\n",
    "            test_predict = dtree.predict(x_test)\n",
    "            print('\\tTesting score (Norm):', metrics.accuracy_score(y_test, test_predict), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18abd663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy score (Freq): 0.5543650793650794\n",
      "Testing score (Freq): 0.6142857142857143 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_criterion = 'gini'\n",
    "dtree_max_depth = 3\n",
    "fold = 10\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion = dtree_criterion, max_depth = dtree_max_depth)\n",
    "\n",
    "\n",
    "scores= cross_val_score(dtree, x_train, y_train, cv= fold, scoring= 'accuracy')\n",
    "print('Validation accuracy score (Freq):',scores.mean())\n",
    "\n",
    "dtree.fit(x_train, y_train)\n",
    "test_predict = dtree.predict(x_test)\n",
    "print('Testing score (Freq):', metrics.accuracy_score(y_test, test_predict), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "265c738d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25 12]\n",
      " [15 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65        37\n",
      "           1       0.60      0.55      0.57        33\n",
      "\n",
      "    accuracy                           0.61        70\n",
      "   macro avg       0.61      0.61      0.61        70\n",
      "weighted avg       0.61      0.61      0.61        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, test_predict))\n",
    "# Print precision, recall and F1\n",
    "print(classification_report(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e0080",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d876f7b",
   "metadata": {},
   "source": [
    "# Pickle to export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd105e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle\n",
    "import pickle\n",
    "# Specify the file name to save the model\n",
    "# Use filename='freq_model.sav' for Freq-PHO-Binary\n",
    "# Use filename='norm_model.sav' for Norm-PHO-Binary\n",
    "filename='norm_model.sav'\n",
    "# Open the file name in write mode. Pass the filename and model.\n",
    "# Replace modelname with the name of your model\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
